{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # For classification\n",
    "from sklearn.ensemble import RandomForestRegressor   # For regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"GUIDE_train.csv\",nrows=100000)\n",
    "null=df.isna().sum()\n",
    "total_length=len(df)\n",
    "per=(null/total_length)*100\n",
    "per=per.sort_values(ascending=False)\n",
    "per=per[per>50].index\n",
    "df.drop(columns=per,inplace=True)\n",
    "df.dropna(subset=['IncidentGrade'], inplace=True)\n",
    "benign_positive = df[df['IncidentGrade'] == 'BenignPositive']\n",
    "true_positive = df[df['IncidentGrade'] == 'TruePositive']\n",
    "false_positive = df[df['IncidentGrade'] == 'FalsePositive']\n",
    "\n",
    "min_size = len(false_positive)\n",
    "benign_positive_downsampled = resample(benign_positive, \n",
    "                                       replace=False, \n",
    "                                       n_samples=min_size, \n",
    "                                       random_state=42)\n",
    "\n",
    "true_positive_downsampled = resample(true_positive, \n",
    "                                     replace=False, \n",
    "                                     n_samples=min_size, \n",
    "                                     random_state=42)\n",
    "\n",
    "false_positive_downsampled = resample(false_positive, \n",
    "                                     replace=False, \n",
    "                                     n_samples=min_size, \n",
    "                                     random_state=42)\n",
    "\n",
    "df = pd.concat([benign_positive_downsampled, \n",
    "                         true_positive_downsampled, \n",
    "                         false_positive_downsampled ])\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df['year'] = df['Timestamp'].dt.year\n",
    "df['month'] = df['Timestamp'].dt.month\n",
    "df['day'] = df['Timestamp'].dt.day\n",
    "df['hour'] = df['Timestamp'].dt.hour\n",
    "df['minute'] = df['Timestamp'].dt.minute\n",
    "df['second'] = df['Timestamp'].dt.second\n",
    "df.drop(columns=[\"Timestamp\"],inplace=True)\n",
    "df.drop(columns=[\"Id\"],inplace=True)\n",
    "\n",
    "Labelencoder=LabelEncoder()\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col]=Labelencoder.fit_transform(df[col])\n",
    "\n",
    "def split(df):\n",
    "    x=df.drop(columns=[\"IncidentGrade\"])\n",
    "    y=df[\"IncidentGrade\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,shuffle=True, stratify=y)\n",
    "    return x,y,X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:53:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "n_df=df[[\"OrgId\",\"IncidentId\",\"AlertId\",\"AlertTitle\",\"day\",\"Category\",\"DetectorId\",\"IncidentGrade\"]]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "x, y, x_train, x_test, y_train, y_test = split(n_df)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [0.2],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Predict with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      4313\n",
      "           1       0.91      0.94      0.92      4313\n",
      "           2       0.95      0.91      0.93      4313\n",
      "\n",
      "    accuracy                           0.92     12939\n",
      "   macro avg       0.92      0.92      0.92     12939\n",
      "weighted avg       0.92      0.92      0.92     12939\n",
      "\n",
      "[[3967  221  125]\n",
      " [ 187 4040   86]\n",
      " [ 196  180 3937]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89      4192\n",
      "           1       0.79      0.88      0.84      2167\n",
      "           2       0.92      0.90      0.91      3641\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.87      0.89      0.88     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[[3656  336  200]\n",
      " [ 158 1917   92]\n",
      " [ 201  160 3280]]\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"GUIDE_test.csv\",nrows=10000)\n",
    "null=df1.isna().sum()\n",
    "total_length=len(df1)\n",
    "per=(null/total_length)*100\n",
    "per=per.sort_values(ascending=False)\n",
    "per=per[per>50].index\n",
    "df1.drop(columns=per,inplace=True)\n",
    "df1.drop(columns=\"Usage\",inplace=True)\n",
    "df1.dropna(subset=[\"IncidentGrade\"])\n",
    "\n",
    "df1['Timestamp'] = pd.to_datetime(df1['Timestamp'])\n",
    "df1['year'] = df1['Timestamp'].dt.year\n",
    "df1['month'] = df1['Timestamp'].dt.month\n",
    "df1['day'] = df1['Timestamp'].dt.day\n",
    "df1['hour'] = df1['Timestamp'].dt.hour\n",
    "df1['minute'] = df1['Timestamp'].dt.minute\n",
    "df1['second'] = df1['Timestamp'].dt.second\n",
    "df1.drop(columns=[\"Timestamp\"],inplace=True)\n",
    "df1.drop(columns=[\"Id\"],inplace=True)\n",
    "Labelencoder=LabelEncoder()\n",
    "for col in df1.select_dtypes(include=\"object\").columns:\n",
    "    df1[col]=Labelencoder.fit_transform(df1[col])\n",
    "\n",
    "t_df=df1[[\"OrgId\",\"IncidentId\",\"AlertId\",\"AlertTitle\",\"day\",\"Category\",\"DetectorId\",\"IncidentGrade\"]]\n",
    "x_test=t_df.drop(columns=\"IncidentGrade\")\n",
    "y_test=t_df[\"IncidentGrade\"]\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
